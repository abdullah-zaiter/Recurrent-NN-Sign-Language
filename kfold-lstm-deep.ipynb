{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kfold-lstm-deep.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"q8R61hWpsVwn"},"source":["**Installing latest pickle to unserialize our data from database**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wO5v_K7u9ky","executionInfo":{"status":"ok","timestamp":1607286784957,"user_tz":180,"elapsed":7624,"user":{"displayName":"Abdullah Zaiter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTkPeS0SHXD3dKxUc_qmh_4VlVzg8f0YHgxI3ZUw=s64","userId":"05259232700742589409"}},"outputId":"97586706-eeb1-471e-b3d3-2ad4f61cc99a"},"source":["!pip install pickle5\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting pickle5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n","\r\u001b[K     |██▌                             | 10kB 29.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 32.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 36.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 32.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 34.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 22.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 23.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 22.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: pickle5\n","  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pickle5: filename=pickle5-0.0.11-cp36-cp36m-linux_x86_64.whl size=218612 sha256=d8e91e2f07fcafff53633d6c2dcbf19cffba283b29ac9d01cf6ee06a06e4f77e\n","  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n","Successfully built pickle5\n","Installing collected packages: pickle5\n","Successfully installed pickle5-0.0.11\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xQPh5dV2smyu"},"source":["**Adding needed imports**"]},{"cell_type":"code","metadata":{"id":"4U3qrcCWt8Pz"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","import  pickle5 as pickle\n","from HandReading import HandReading\n","from Imu import Imu\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, LSTM\n","from sklearn.metrics import accuracy_score as acc\n","from tensorflow.keras.utils import plot_model\n","from sklearn.metrics import classification_report, confusion_matrix\n","from tensorflow.keras.callbacks import EarlyStopping"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NxkiVf5nstVD"},"source":["**Creating dictionary mappers**\n"]},{"cell_type":"code","metadata":{"id":"JA3Wykk635oS"},"source":["dict_word_id = {}\n","dict_id_word = {}\n","\n","list_word = os.listdir('/content/drive/MyDrive/database') \n","for j in range(len(list_word)) : \n","  dict_word_id[list_word[j]] = j\n","  dict_id_word[j] = list_word[j]\n","print(dict_word_id)\n","print(dict_id_word)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gsy9R6SatbOP"},"source":["**Preparing input and labels data**"]},{"cell_type":"code","metadata":{"id":"tWsGipmkutvS"},"source":["input_data, output = [], []\n","\n","list_word = os.listdir('/content/drive/MyDrive/database') \n","\n","for word in list_word:\n","  list_pickle_file = os.listdir(f'/content/drive/MyDrive/database/{word}')\n","  k = 0 \n","  for pickle_file in list_pickle_file:\n","    k+=1\n","    with open(f'/content/drive/MyDrive/database/{word}/{pickle_file}', 'rb') as input:\n","      readings = pickle.load(input)\n","      for reading in readings:\n","        finger = []\n","        for i in range(5):\n","          finger.append(np.float16(reading.imus[i].accel[0]/255.0))\n","          finger.append(np.float16(reading.imus[i].accel[1]/255.0))\n","          finger.append(np.float16(reading.imus[i].accel[2]/255.0))\n","          finger.append(np.float16(reading.imus[i].gyro[0]/255.0))\n","          finger.append(np.float16(reading.imus[i].gyro[1]/255.0))\n","          finger.append(np.float16(reading.imus[i].gyro[2]/255.0))\n","          pass\n","      \n","        input_data.append(finger)\n","        \n","        out = np.zeros(11)\n","        out[dict_word_id[word]] = 1.0\n","        output.append(out)\n","\n","input_data = np.array(input_data)\n","input_data = input_data.reshape((input_data.shape[0], input_data.shape[1], 1))\n","output = np.array(output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJLjr6Wks6P1"},"source":["**Creating neural network model**"]},{"cell_type":"code","metadata":{"id":"G2VmEeNCsJ-4"},"source":["model = Sequential()\n","\n","model.add(LSTM(units=50, input_shape=input_data[0].shape, return_sequences=True))\n","model.add(Dropout(0.2))\n","\n","model.add(LSTM(50, return_sequences=True))\n","model.add(Dropout(0.2))\n","\n","model.add(LSTM(50, return_sequences=True))\n","model.add(Dropout(0.2))\n","\n","model.add(LSTM(units=50))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(11, activation='softmax'))\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PeUJrzZbt5lx"},"source":["**Separate data and train**"]},{"cell_type":"code","metadata":{"id":"m2kVwlsJPE2J"},"source":["from sklearn.model_selection import StratifiedKFold\n","kfoldK = 10\n","kfold = StratifiedKFold(n_splits=10, shuffle=True)\n","callback = EarlyStopping(monitor='val_accuracy', min_delta = 0.001, patience=3)\n","iterations = 0 \n","sumOfAccuracy = 0\n","maxepoch = 100\n","for train, test in kfold.split(input_data, output.argmax(1)):\n","  iterations += 1\n","  trainX, testX = input_data[train], input_data[test]\n","  trainY, testY = output[train], output[test]\n","\n","  trainX, validX, trainY, validY = train_test_split(\n","    trainX, trainY, test_size=0.3, stratify=trainY, random_state=42)\n","  \n","  model.fit(trainX, trainY, epochs=maxepoch, batch_size=32, verbose=2, callbacks=[callback], validation_data=(validX, validY))\n","  predicted = model.predict(testX)\n","  pred = []\n","  for j in predicted:\n","    arg = np.argmax(j)\n","    pred.append(arg)\n","  pred = np.array(pred)\n","  y_one = []\n","  for y in testY :\n","    arg = np.argmax(y)\n","    y_one.append(arg)\n","  y_one = np.array(y_one)\n","  sumOfAccuracy += acc(y_one,pred)\n","  avgAccuray = sumOfAccuracy/iterations\n","  print(f\"average accuracy = {avgAccuray}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C71psesJwyrp"},"source":["**Analyse accuracies**\n"]},{"cell_type":"code","metadata":{"id":"1nJueJzDPE8W"},"source":["prd = model.predict(testX)\n","pred = []\n","for j in range(len(prd)):\n","  lis = prd[j]\n","  arg = np.argmax(lis)\n","  pred.append(arg)\n","pred = np.array(pred)\n","\n","y_one = []\n","for y in testY :\n","  arg = np.argmax(y)\n","  y_one.append(arg)\n","y_one = np.array(y_one)\n","\n","print(classification_report(y_one, pred))\n","print(dict_id_word)\n","print()\n","print(acc(y_one,pred))\n","print(f\"average accuracy = {sumOfAccuracy/iterations}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6edt2gJkvGtN"},"source":["**Real life usage example**"]},{"cell_type":"code","metadata":{"id":"mC1PvHsuY_jJ"},"source":["with open(f'/content/drive/MyDrive/database/prazer-em-te-conhecer/3.pkl', 'rb') as input:\n","  readings = pickle.load(input)\n","  input_test_data = []\n","  j = 0\n","  for reading in readings:\n","    finger = []\n","    for i in range(5):\n","      finger.append(np.float16(reading.imus[i].accel[0]/255.0))\n","      finger.append(np.float16(reading.imus[i].accel[1]/255.0))\n","      finger.append(np.float16(reading.imus[i].accel[2]/255.0))\n","      finger.append(np.float16(reading.imus[i].gyro[0]/255.0))\n","      finger.append(np.float16(reading.imus[i].gyro[1]/255.0))\n","      finger.append(np.float16(reading.imus[i].gyro[2]/255.0))\n","    \n","  \n","    input_test_data.append(finger)\n","    \n","input_test_data = np.array(input_test_data)\n","input_test_data = input_test_data.reshape((input_test_data.shape[0], input_test_data.shape[1], 1))\n","\n","for inputData in input_test_data:\n","  result1 = model.predict(inputData.reshape(1,30,1))\n","  print(dict_id_word[np.argmax(result1)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WnmI6_hrvAR_"},"source":["**Plot model structure**"]},{"cell_type":"code","metadata":{"id":"YNEPCZBjVRBb"},"source":["plot_model(model, to_file='topology.png',show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ESiumKA5Xe8"},"source":["model.save(f\"deep-lstm-{maxepoch}maxepoch-k{kfoldK}fold-{avgAccuray}avgacc.h5\", save_format='.h5')\n","model.save(f\"deep-lstm-{maxepoch}maxepoch-k{kfoldK}fold-{avgAccuray}avgacc\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbxmz017Dqdh"},"source":["cm = confusion_matrix(y_one, pred)\n","print(cm)\n","plt.rcParams[\"figure.figsize\"] = (20,8)\n","plt.imshow(cm, cmap=plt.cm.Reds)\n","plt.xlabel(\"Sinais obtidos\")\n","plt.ylabel(\"Sinais corretos\")\n","tick_marks = np.arange(len(list(dict_word_id.keys())[:-1]))\n","plt.tick_params(axis='both', which='major', labelsize=12)\n","plt.xticks(tick_marks, list(dict_word_id.keys())[:-1], rotation=60)\n","plt.yticks(tick_marks, list(dict_word_id.keys())[:-1])\n","plt.title('Matriz de Confusão')\n","plt.colorbar()\n","plt.show()"],"execution_count":null,"outputs":[]}]}